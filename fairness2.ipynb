{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Requirement already satisfied: aif360 in c:\\users\\nicolas\\appdata\\roaming\\python\\python39\\site-packages (0.6.0)\n",
            "Requirement already satisfied: pandas>=0.24.0 in c:\\users\\nicolas\\appdata\\roaming\\python\\python39\\site-packages (from aif360) (2.1.0)\n",
            "Requirement already satisfied: scipy>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from aif360) (1.9.1)\n",
            "Requirement already satisfied: numpy>=1.16 in c:\\users\\nicolas\\appdata\\roaming\\python\\python39\\site-packages (from aif360) (1.24.4)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in c:\\users\\nicolas\\appdata\\roaming\\python\\python39\\site-packages (from aif360) (1.3.1)\n",
            "Requirement already satisfied: matplotlib in c:\\programdata\\anaconda3\\lib\\site-packages (from aif360) (3.5.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360) (2.8.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in c:\\users\\nicolas\\appdata\\roaming\\python\\python39\\site-packages (from pandas>=0.24.0->aif360) (2023.4)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.24.0->aif360) (2022.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nicolas\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn>=1.0->aif360) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nicolas\\appdata\\roaming\\python\\python39\\site-packages (from scikit-learn>=1.0->aif360) (3.2.0)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (9.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (3.0.9)\n",
            "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (21.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (1.4.2)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib->aif360) (4.25.0)\n",
            "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas>=0.24.0->aif360) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install aif360"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Gender as sensitive features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "df=pd.read_csv('./recruitmentdataset-2022-1.3.csv')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df['gender'] = df['gender'].map({'male': 1, 'female': 2, 'other': 3})\n",
        "df['nationality']=df['nationality'].map({'Dutch': 1, 'Belgian': 2,'German':3})\n",
        "\n",
        "\n",
        "# Replace boolean values with 0 and 1\n",
        "df = pd.get_dummies(df.drop('Id',axis=1))\n",
        "\n",
        "df = df.replace({False: 0, True: 1})\n",
        "\n",
        "# Min-max scaling of columns age, ind-university_grade and ind-languages\n",
        "df['age'] = (df['age'] - df['age'].min()) / (df['age'].max() - df['age'].min())\n",
        "df['ind-university_grade'] = (df['ind-university_grade'] - df['ind-university_grade'].min()) / (df['ind-university_grade'].max() - df['ind-university_grade'].min())\n",
        "df['ind-languages'] = (df['ind-languages'] - df['ind-languages'].min()) / (df['ind-languages'].max() - df['ind-languages'].min())\n",
        "\n",
        "X = df.drop(['decision'], axis=1)\n",
        "y = df['decision']\n",
        "\n",
        "# One-hot encode the target variable (one column for each class)\n",
        "y = y.replace({False: 0, True: 1})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      gender       age  nationality  ind-university_grade  ind-debateclub  \\\n",
            "3994       1  0.545455            1              0.727273               0   \n",
            "423        2  0.545455            1              0.484848               0   \n",
            "2991       1  0.636364            1              0.575758               1   \n",
            "1221       2  0.454545            1              0.545455               1   \n",
            "506        1  0.454545            1              0.545455               1   \n",
            "...      ...       ...          ...                   ...             ...   \n",
            "1130       2  0.363636            1              0.636364               0   \n",
            "1294       3  0.636364            1              0.363636               0   \n",
            "860        2  0.545455            1              0.636364               0   \n",
            "3507       1  0.454545            3              0.606061               0   \n",
            "3174       2  0.636364            2              0.666667               0   \n",
            "\n",
            "      ind-programming_exp  ind-international_exp  ind-entrepeneur_exp  \\\n",
            "3994                    1                      0                    0   \n",
            "423                     0                      1                    0   \n",
            "2991                    0                      0                    0   \n",
            "1221                    0                      1                    1   \n",
            "506                     0                      1                    1   \n",
            "...                   ...                    ...                  ...   \n",
            "1130                    1                      0                    1   \n",
            "1294                    0                      0                    1   \n",
            "860                     0                      0                    0   \n",
            "3507                    1                      0                    0   \n",
            "3174                    1                      0                    0   \n",
            "\n",
            "      ind-languages  ind-exact_study  ...  sport_Running  sport_Swimming  \\\n",
            "3994       0.333333                1  ...              0               0   \n",
            "423        0.666667                0  ...              0               0   \n",
            "2991       0.666667                1  ...              0               0   \n",
            "1221       1.000000                0  ...              0               0   \n",
            "506        0.666667                0  ...              0               0   \n",
            "...             ...              ...  ...            ...             ...   \n",
            "1130       0.666667                1  ...              0               1   \n",
            "1294       0.666667                0  ...              0               0   \n",
            "860        0.333333                1  ...              1               0   \n",
            "3507       0.333333                1  ...              0               1   \n",
            "3174       0.333333                1  ...              0               0   \n",
            "\n",
            "      sport_Tennis  ind-degree_bachelor  ind-degree_master  ind-degree_phd  \\\n",
            "3994             0                    0                  1               0   \n",
            "423              0                    1                  0               0   \n",
            "2991             0                    1                  0               0   \n",
            "1221             1                    0                  0               1   \n",
            "506              0                    0                  1               0   \n",
            "...            ...                  ...                ...             ...   \n",
            "1130             0                    1                  0               0   \n",
            "1294             1                    1                  0               0   \n",
            "860              0                    1                  0               0   \n",
            "3507             0                    1                  0               0   \n",
            "3174             0                    0                  1               0   \n",
            "\n",
            "      company_A  company_B  company_C  company_D  \n",
            "3994          0          0          0          1  \n",
            "423           1          0          0          0  \n",
            "2991          0          0          1          0  \n",
            "1221          0          1          0          0  \n",
            "506           1          0          0          0  \n",
            "...         ...        ...        ...        ...  \n",
            "1130          0          1          0          0  \n",
            "1294          0          1          0          0  \n",
            "860           1          0          0          0  \n",
            "3507          0          0          0          1  \n",
            "3174          0          0          0          1  \n",
            "\n",
            "[3200 rows x 25 columns]\n"
          ]
        }
      ],
      "source": [
        "print(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data: 0.82\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "clf = SVC(kernel='rbf', C=1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print('Accuracy on test data:', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "id": "FNDVQ087Rk1C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original fairness metric: 0.026344484081577746\n",
            "Transformed fairness metric: 0.0\n"
          ]
        }
      ],
      "source": [
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "\n",
        "# Assuming the column 'gender' represents the sensitive attribute\n",
        "# Replace 'gender' with the name of the column you want to evaluate bias on\n",
        "\n",
        "sensitive_column = 'gender'\n",
        "column_index = df.columns.get_loc(sensitive_column)\n",
        "\n",
        "# Create a BinaryLabelDataset\n",
        "\n",
        "privileged_groups = [{sensitive_column: 2}]  # 1 is the privileged\n",
        "unprivileged_groups = [{sensitive_column: 1,sensitive_column:3}]  # 2 is the unprivileged\n",
        "bld = BinaryLabelDataset(df=df, label_names=['decision'], protected_attribute_names=[sensitive_column],\n",
        "                        unprivileged_protected_attributes=[unprivileged_groups])\n",
        "\n",
        "# Compute fairness metric on original training dataset\n",
        "metric_orig = BinaryLabelDatasetMetric(bld, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "print('Original fairness metric:', metric_orig.mean_difference())\n",
        "\n",
        "# Transform the original dataset to a fair representation\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "bld_transformed = RW.fit_transform(bld)\n",
        "\n",
        "# Compute fairness metric on the transformed dataset\n",
        "metric_modification = BinaryLabelDatasetMetric(bld_transformed, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "print('Transformed fairness metric:', metric_modification.mean_difference())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data after reweighing: 0.8575\n"
          ]
        }
      ],
      "source": [
        "X_train_rw = bld_transformed.features\n",
        "y_train_rw = bld_transformed.labels.ravel()\n",
        "\n",
        "clf_rw = SVC(kernel='rbf', C=1)\n",
        "clf_rw.fit(X_train_rw, y_train_rw)\n",
        "\n",
        "y_pred_rw = clf_rw.predict(X_test)\n",
        "print('Accuracy on test data after reweighing:', accuracy_score(y_test, y_pred_rw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Nationality as sensitive information"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "df=pd.read_csv('./recruitmentdataset-2022-1.3.csv')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df['gender'] = df['gender'].map({'male': 1, 'female': 2, 'other': 3})\n",
        "df['nationality']=df['nationality'].map({'Dutch': 1, 'Belgian': 2,'German':3})\n",
        "\n",
        "\n",
        "# Replace boolean values with 0 and 1\n",
        "df = pd.get_dummies(df.drop('Id',axis=1))\n",
        "\n",
        "df = df.replace({False: 0, True: 1})\n",
        "\n",
        "# Min-max scaling of columns age, ind-university_grade and ind-languages\n",
        "df['age'] = (df['age'] - df['age'].min()) / (df['age'].max() - df['age'].min())\n",
        "df['ind-university_grade'] = (df['ind-university_grade'] - df['ind-university_grade'].min()) / (df['ind-university_grade'].max() - df['ind-university_grade'].min())\n",
        "df['ind-languages'] = (df['ind-languages'] - df['ind-languages'].min()) / (df['ind-languages'].max() - df['ind-languages'].min())\n",
        "\n",
        "X = df.drop(['decision'], axis=1)\n",
        "y = df['decision']\n",
        "\n",
        "# One-hot encode the target variable (one column for each class)\n",
        "y = y.replace({False: 0, True: 1})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data: 0.82\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "clf = SVC(kernel='rbf', C=1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print('Accuracy on test data:', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original fairness metric: -0.00984228194267206\n",
            "Transformed fairness metric: -1.6653345369377348e-16\n"
          ]
        }
      ],
      "source": [
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "\n",
        "# Assuming the column 'gender' represents the sensitive attribute\n",
        "# Replace 'gender' with the name of the column you want to evaluate bias on\n",
        "\n",
        "sensitive_column = 'nationality'\n",
        "column_index = df.columns.get_loc(sensitive_column)\n",
        "\n",
        "# Create a BinaryLabelDataset\n",
        "\n",
        "privileged_groups = [{sensitive_column: 1}]  # 1 is the privileged\n",
        "unprivileged_groups = [{sensitive_column: 3,sensitive_column:2}]  # 2 is the unprivileged\n",
        "bld = BinaryLabelDataset(df=df, label_names=['decision'], protected_attribute_names=[sensitive_column],\n",
        "                        unprivileged_protected_attributes=[unprivileged_groups])\n",
        "\n",
        "# Compute fairness metric on original training dataset\n",
        "metric_orig = BinaryLabelDatasetMetric(bld, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "print('Original fairness metric:', metric_orig.mean_difference())\n",
        "\n",
        "# Transform the original dataset to a fair representation\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "bld_transformed = RW.fit_transform(bld)\n",
        "\n",
        "# Compute fairness metric on the transformed dataset\n",
        "metric_modification = BinaryLabelDatasetMetric(bld_transformed, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "print('Transformed fairness metric:', metric_modification.mean_difference())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data after reweighing: 0.8575\n"
          ]
        }
      ],
      "source": [
        "X_train_rw = bld_transformed.features\n",
        "y_train_rw = bld_transformed.labels.ravel()\n",
        "\n",
        "clf_rw = SVC(kernel='rbf', C=1)\n",
        "clf_rw.fit(X_train_rw, y_train_rw)\n",
        "\n",
        "y_pred_rw = clf_rw.predict(X_test)\n",
        "print('Accuracy on test data after reweighing:', accuracy_score(y_test, y_pred_rw))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Both at once"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "df=pd.read_csv('./recruitmentdataset-2022-1.3.csv')\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "df['gender'] = df['gender'].map({'male': 1, 'female': 2, 'other': 3})\n",
        "df['nationality']=df['nationality'].map({'Dutch': 1, 'Belgian': 2,'German':3})\n",
        "\n",
        "\n",
        "# Replace boolean values with 0 and 1\n",
        "df = pd.get_dummies(df.drop('Id',axis=1))\n",
        "\n",
        "df = df.replace({False: 0, True: 1})\n",
        "\n",
        "# Min-max scaling of columns age, ind-university_grade and ind-languages\n",
        "df['age'] = (df['age'] - df['age'].min()) / (df['age'].max() - df['age'].min())\n",
        "df['ind-university_grade'] = (df['ind-university_grade'] - df['ind-university_grade'].min()) / (df['ind-university_grade'].max() - df['ind-university_grade'].min())\n",
        "df['ind-languages'] = (df['ind-languages'] - df['ind-languages'].min()) / (df['ind-languages'].max() - df['ind-languages'].min())\n",
        "\n",
        "X = df.drop(['decision'], axis=1)\n",
        "y = df['decision']\n",
        "\n",
        "# One-hot encode the target variable (one column for each class)\n",
        "y = y.replace({False: 0, True: 1})\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data: 0.82\n"
          ]
        }
      ],
      "source": [
        "\n",
        "X_train = X_train.to_numpy()\n",
        "X_test = X_test.to_numpy()\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "\n",
        "clf = SVC(kernel='rbf', C=1)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "print('Accuracy on test data:', accuracy_score(y_test, y_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Original fairness metric: -0.04329662899642617\n",
            "Transformed fairness metric: -5.551115123125783e-17\n"
          ]
        }
      ],
      "source": [
        "from aif360.datasets import BinaryLabelDataset\n",
        "from aif360.metrics import BinaryLabelDatasetMetric\n",
        "from aif360.algorithms.preprocessing import Reweighing\n",
        "\n",
        "# Assuming the column 'gender' represents the sensitive attribute\n",
        "# Replace 'gender' with the name of the column you want to evaluate bias on\n",
        "\n",
        "sensitive_column = ['gender','nationality']\n",
        "\n",
        "\n",
        "# Create a BinaryLabelDataset\n",
        "\n",
        "privileged_groups = [{'gender': 1,'nationality': 1}]  # 1 is the privileged\n",
        "unprivileged_groups = [{'gender': 2,'gender':3},{'nationality': 2,'nationality': 3}]  # 2 is the unprivileged\n",
        "bld = BinaryLabelDataset(df=df, label_names=['decision'], protected_attribute_names=['gender','nationality'],\n",
        "                        unprivileged_protected_attributes=[unprivileged_groups])\n",
        "\n",
        "# Compute fairness metric on original training dataset\n",
        "metric_orig = BinaryLabelDatasetMetric(bld, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "print('Original fairness metric:', metric_orig.mean_difference())\n",
        "\n",
        "# Transform the original dataset to a fair representation\n",
        "RW = Reweighing(unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "bld_transformed = RW.fit_transform(bld)\n",
        "\n",
        "# Compute fairness metric on the transformed dataset\n",
        "metric_modification = BinaryLabelDatasetMetric(bld_transformed, unprivileged_groups=unprivileged_groups, privileged_groups=privileged_groups)\n",
        "print('Transformed fairness metric:', metric_modification.mean_difference())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 161,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy on test data after reweighing: 0.8575\n"
          ]
        }
      ],
      "source": [
        "X_train_rw = bld_transformed.features\n",
        "y_train_rw = bld_transformed.labels.ravel()\n",
        "\n",
        "clf_rw = SVC(kernel='rbf', C=1)\n",
        "clf_rw.fit(X_train_rw, y_train_rw)\n",
        "\n",
        "y_pred_rw = clf_rw.predict(X_test)\n",
        "print('Accuracy on test data after reweighing:', accuracy_score(y_test, y_pred_rw))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
